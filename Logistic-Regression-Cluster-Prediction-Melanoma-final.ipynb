{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riaz cohort APM-cluster prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset122 = pd.read_csv('cohort_liu.csv')\n",
    "\n",
    "dataset40 = pd.read_csv('cohort_van_allen.csv')\n",
    "\n",
    "frames = [dataset122,dataset40]\n",
    "\n",
    "dataset_orig = pd.concat(frames)\n",
    "dataset=dataset_orig[['cluster',\"HLA_A\",\"HLA_B\",\"HLA_C\",\"HLA_DRA\", \"HLA_DRB1\",\"HLA_DQA1\",\"HLA_DQB1\",\"HLA_DPA1\",\"HLA_DPB1\",\n",
    "                      'PSME1','TAPBP','NLRC5','PSMB10','TAP2','HLA_DRB6','HLA_DQA2','HLA_DQB2','CIITA','HLA_E','HLA_G','HLA_F','HLA_DMA','HLA_DOB']]\n",
    "dataset.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset.isna().sum()\n",
    "dataset = dataset.dropna()\n",
    "dataset.shape\n",
    "dataset['cluster']=dataset['cluster'].astype('uint8')\n",
    "dataset.shape\n",
    "dataset.cluster.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling from each class since some classes may have low number of cases\n",
    "frac=0.9\n",
    "random_state=0\n",
    "\n",
    "c1=dataset[dataset['cluster']==1]\n",
    "c1_train_set = c1.sample(frac=frac, random_state=random_state)\n",
    "c1_test_set = c1.drop(c1_train_set.index)\n",
    "\n",
    "c2=dataset[dataset['cluster']==2]\n",
    "c2_train_set = c2.sample(frac=frac, random_state=random_state)\n",
    "c2_test_set = c2.drop(c2_train_set.index)\n",
    "\n",
    "c3=dataset[dataset['cluster']==3]\n",
    "c3_train_set = c3.sample(frac=frac, random_state=random_state)\n",
    "c3_test_set = c3.drop(c3_train_set.index)\n",
    "\n",
    "c4=dataset[dataset['cluster']==4]\n",
    "c4_train_set = c4.sample(frac=frac, random_state=random_state)\n",
    "c4_test_set = c4.drop(c4_train_set.index)\n",
    "\n",
    "train_frames=[c1_train_set,c2_train_set,c3_train_set,c4_train_set]\n",
    "train_set=pd.concat(train_frames)\n",
    "test_frames=[c1_test_set,c2_test_set,c3_test_set,c4_test_set]\n",
    "test_set=pd.concat(test_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_set.copy()\n",
    "test_features = test_set.copy()\n",
    "\n",
    "train_labels = train_features.pop('cluster')\n",
    "test_labels = test_features.pop('cluster')\n",
    "\n",
    "X_train=pd.DataFrame.to_numpy(train_features)\n",
    "y_train=pd.Series.to_numpy(train_labels)\n",
    "\n",
    "X_test=pd.DataFrame.to_numpy(test_features)\n",
    "y_test=pd.Series.to_numpy(test_labels)\n",
    "\n",
    "X=np.concatenate((X_train,X_test),axis=0)\n",
    "y=np.concatenate((y_train,y_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver=\"saga\", random_state=0, max_iter=1500,C=8)\n",
    "clf.fit(X_train, y_train)\n",
    "y_score=clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "fprs = []\n",
    "tprs = []\n",
    "aucs = []\n",
    "\n",
    "for i in range(1000):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "        clf = LogisticRegression(solver=\"saga\", random_state=0, max_iter=1500,C=8)\n",
    "\n",
    "        y_score=clf.fit(X[train], y[train]).predict_proba(X[test])\n",
    "        y_train_bin = label_binarize(y[train], classes=[1,2,3,4])\n",
    "        y_test_bin = label_binarize(y[test], classes=[1,2,3,4])\n",
    "        n_classes = y_train_bin.shape[1]\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "        tprs.append(tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        fprs.append(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_microAUC=0\n",
    "for i in range(len(aucs)):\n",
    "    sum_microAUC += aucs[i]['micro']\n",
    "print('mean micro AUC =',sum_microAUC/len(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset2 = pd.read_csv('cohort_riaz-pre-treatment.csv')\n",
    "\n",
    "\n",
    "dataset_orig2 = raw_dataset2.copy()\n",
    "dataset2=dataset_orig2[[\"HLA_A\",\"HLA_B\",\"HLA_C\",\"HLA_DRA\", \"HLA_DRB1\",\"HLA_DQA1\",\"HLA_DQB1\",\"HLA_DPA1\",\"HLA_DPB1\",\n",
    "                      'PSME1','TAPBP','NLRC5','PSMB10','TAP2','HLA_DRB6','HLA_DQA2','HLA_DQB2','CIITA','HLA_E','HLA_G','HLA_F','HLA_DMA','HLA_DOB']]\n",
    "\n",
    "dataset2.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset2.isna().sum()\n",
    "dataset2 = dataset2.dropna()\n",
    "X_pred=pd.DataFrame.to_numpy(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict by logistic regression classifer\n",
    "clf = LogisticRegression(solver=\"saga\", random_state=0, max_iter=1500,C=8)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "y_pred=clf.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset2['pred_cluster']=y_pred\n",
    "raw_dataset2.to_csv('riaz_pred_cluster.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scRNA pseudobulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset2 = pd.read_csv('scRNA-pseudobulk-for-clustering.csv')\n",
    "\n",
    "\n",
    "dataset_orig2 = raw_dataset2.copy()\n",
    "dataset2=dataset_orig2[[\"HLA_A\",\"HLA_B\",\"HLA_C\",\"HLA_DRA\", \"HLA_DRB1\",\"HLA_DQA1\",\"HLA_DQB1\",\"HLA_DPA1\",\"HLA_DPB1\",\n",
    "                      'PSME1','TAPBP','NLRC5','PSMB10','TAP2','HLA_DRB6','HLA_DQA2','HLA_DQB2','CIITA','HLA_E','HLA_G','HLA_F','HLA_DMA','HLA_DOB']]\n",
    "\n",
    "dataset2.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset2.isna().sum()\n",
    "dataset2 = dataset2.dropna()\n",
    "\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred=pd.DataFrame.to_numpy(dataset2)\n",
    "\n",
    "# Predict by logistic regression classifer\n",
    "clf = LogisticRegression(solver=\"saga\", random_state=0, max_iter=1500,C=8)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "y_pred=clf.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset2['pred_cluster']=y_pred\n",
    "raw_dataset2.to_csv('pseudobulk-clustering-pred.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
